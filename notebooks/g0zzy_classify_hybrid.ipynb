{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2e378f9",
   "metadata": {},
   "source": [
    "\"Feature-based transfer learningâ€ in NLP.\n",
    "\n",
    "* Pre-trained DL model = feature extractor.\n",
    "\n",
    "* ML algorithm = downstream task solver.\n",
    "\n",
    "HYBRID: Itâ€™s not â€œpure deep learningâ€ (since youâ€™re not training/fine-tuning the whole transformer end-to-end).\n",
    "\n",
    "Itâ€™s also not â€œpure machine learningâ€ (since your features are learned by a deep neural network, not hand-crafted)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdc8cc6",
   "metadata": {},
   "source": [
    "### SBERT + Logistic Regression = Deep learning for embeddings + Machine learning for classification â†’ a hybrid approach thatâ€™s especially effective for small/medium labeled datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bde9f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Loading the dataset\n",
    "path = \"/Users/gozde/code/g0zzy/stress_sense/raw_data/Data.csv\"\n",
    "data = pd.read_csv(path)\n",
    "\n",
    "data.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "data.dropna(inplace=True)\n",
    "data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9aac7b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def strip_urls(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove URLs (http, https, www, youtu links) from a string.\n",
    "    \"\"\"\n",
    "    # remove http/https URLs\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    # remove www.* URLs\n",
    "    text = re.sub(r\"www\\.\\S+\", \"\", text)\n",
    "    # remove youtube short links\n",
    "    text = re.sub(r\"youtu\\.be\\S+\", \"\", text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f350c2e0",
   "metadata": {},
   "source": [
    "## Cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b22f23f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.statement = data.statement.apply(strip_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59474b0a",
   "metadata": {},
   "source": [
    "## Only classify stress, anxiety and normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a49a0fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Normal': 16040, 'Anxiety': 3623, 'Stress': 2296})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "TARGET = {\"Stress\", \"Anxiety\", \"Normal\"}\n",
    "\n",
    "# 1) Filter to the 3 classes\n",
    "df = data.dropna(subset=[\"statement\",\"status\"])\n",
    "df = df[df[\"status\"].isin(TARGET)].reset_index(drop=True)\n",
    "\n",
    "texts  = df[\"statement\"].tolist()\n",
    "labels = df[\"status\"].tolist()\n",
    "print(Counter(labels))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42, stratify=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fde3f523",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gozde/.pyenv/versions/3.10.6/envs/stress_sense/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 549/549 [00:23<00:00, 23.73it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 138/138 [00:05<00:00, 25.89it/s]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "sbert = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Encode (normalize for cosine/logreg stability)\n",
    "E_train = sbert.encode(X_train, normalize_embeddings=True, show_progress_bar=True)\n",
    "E_test  = sbert.encode(X_test,  normalize_embeddings=True, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2af3d2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert.save(\"../models/sbert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aee37bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.29728255e-02,  9.66348425e-02, -2.12916755e-03,\n",
       "         7.82683119e-02, -6.41745795e-03,  3.80002335e-02,\n",
       "         9.46167856e-02,  3.93962167e-04, -5.45614287e-02,\n",
       "         1.48365507e-02,  1.35712266e-01, -7.15561882e-02,\n",
       "         1.98368244e-02,  4.60874522e-03,  2.93407235e-02,\n",
       "        -2.44426429e-02,  2.55676303e-02, -3.15778330e-02,\n",
       "        -6.94974065e-02,  2.44781375e-03,  4.08358239e-02,\n",
       "        -1.56645086e-02,  6.57425355e-03,  4.47515920e-02,\n",
       "         4.42355545e-03,  5.28066866e-02, -5.22431955e-02,\n",
       "         2.03372296e-02,  7.58799985e-02, -2.19202787e-02,\n",
       "        -2.24517044e-02,  2.38462687e-02,  9.50959045e-03,\n",
       "         8.76056328e-02,  5.16428873e-02, -5.79361245e-03,\n",
       "         6.01320434e-03,  2.46345298e-03,  1.73994303e-02,\n",
       "        -2.02387641e-03, -1.28350954e-03, -1.18024223e-01,\n",
       "         6.54889569e-02, -1.59119023e-03,  2.21067723e-02,\n",
       "         3.98671394e-03, -5.12573980e-02,  4.59731221e-02,\n",
       "        -5.94871677e-02, -4.02599275e-02, -4.32095118e-02,\n",
       "        -4.56050262e-02, -8.21539238e-02, -3.29703577e-02,\n",
       "        -1.93325933e-02,  3.19093652e-02,  6.29870407e-03,\n",
       "         5.59611712e-03, -4.56801197e-03,  6.45429455e-03,\n",
       "        -7.08487397e-03, -3.66104320e-02, -7.68164247e-02,\n",
       "         4.68343198e-02,  1.07686520e-01, -2.29284577e-02,\n",
       "        -1.79801360e-02, -8.53630006e-02, -5.53470775e-02,\n",
       "         4.30554450e-02, -2.59934235e-02,  3.70318554e-02,\n",
       "         5.14611602e-03,  3.12301069e-02, -1.42374756e-02,\n",
       "         3.78846703e-03,  6.97221560e-03, -7.23819137e-02,\n",
       "         9.77919400e-02,  4.59001400e-03, -5.24475351e-02,\n",
       "        -1.34153813e-01, -1.77996363e-02,  5.57135716e-02,\n",
       "         3.77226137e-02,  2.64264829e-02,  8.52380916e-02,\n",
       "        -4.34715413e-02, -1.15083732e-01,  3.01381871e-02,\n",
       "         1.15143955e-02, -6.90703839e-02,  1.49322627e-03,\n",
       "         2.94745304e-02, -2.51136236e-02,  4.44448926e-02,\n",
       "        -4.78883609e-02, -4.57312986e-02,  4.33189049e-02,\n",
       "         1.61351070e-01,  5.57281077e-02,  4.23104614e-02,\n",
       "         1.16117485e-02, -3.55468318e-02, -1.21924140e-01,\n",
       "        -5.99862225e-02,  1.06153861e-02, -9.00767222e-02,\n",
       "         6.93381950e-02, -3.75782326e-02, -5.66841569e-04,\n",
       "         1.03533743e-02,  4.50851694e-02,  9.31746699e-03,\n",
       "        -3.90490890e-02, -2.69061122e-02, -9.38311815e-02,\n",
       "         6.03033230e-02, -6.05729297e-02,  3.28136906e-02,\n",
       "         5.88000119e-02,  5.55175580e-02, -9.09304433e-03,\n",
       "        -4.12377808e-03, -3.34346853e-02, -4.47558500e-02,\n",
       "         1.13295503e-01, -4.37911061e-33, -5.27266180e-03,\n",
       "        -6.72027245e-02,  4.43590321e-02,  4.94091772e-02,\n",
       "        -2.44420376e-02,  3.22087370e-02, -2.78077852e-02,\n",
       "         1.01029031e-01, -3.52156423e-02,  4.52208295e-02,\n",
       "        -2.08255798e-02, -9.83219519e-02,  1.12822810e-02,\n",
       "         3.84233184e-02,  4.92548086e-02,  8.08036923e-02,\n",
       "        -3.31730805e-02,  2.71390174e-02, -2.65450887e-02,\n",
       "         3.52762863e-02,  4.14838605e-02, -3.51199061e-02,\n",
       "        -1.05239647e-02, -6.64989278e-02, -6.74167722e-02,\n",
       "        -8.51691589e-02,  6.18812256e-03, -3.08593661e-02,\n",
       "        -4.21840847e-02,  9.47032496e-03, -3.96481827e-02,\n",
       "        -3.21099646e-02, -6.27840087e-02,  7.61146918e-02,\n",
       "         4.82236408e-02,  5.98350316e-02,  5.41525707e-02,\n",
       "        -4.20566462e-02,  2.69581303e-02, -3.92408721e-04,\n",
       "        -8.32631066e-02, -1.83575638e-02,  2.65993979e-02,\n",
       "         3.20607163e-02,  5.26300482e-02, -1.25841796e-02,\n",
       "        -2.19656993e-02,  9.44054499e-03,  4.26766612e-02,\n",
       "         3.49450707e-02, -1.47352731e-02,  5.73520809e-02,\n",
       "         1.44527555e-02, -1.42789930e-02,  7.73955882e-02,\n",
       "         6.93497211e-02,  2.40205731e-02,  2.13899538e-02,\n",
       "         2.30211820e-02,  7.47722834e-02,  4.96241488e-02,\n",
       "         3.99097502e-02, -2.17058957e-02,  6.90038279e-02,\n",
       "         1.64576806e-02,  1.00794211e-02, -5.32856807e-02,\n",
       "        -1.13038696e-01,  1.08548634e-01,  3.87234762e-02,\n",
       "        -4.46830988e-02, -6.33711740e-02, -4.62801903e-02,\n",
       "         4.61921617e-02, -1.91594362e-02, -7.42104929e-03,\n",
       "         2.24480014e-02,  7.43453726e-02, -1.18145859e-02,\n",
       "        -6.67349100e-02,  8.25936347e-02, -8.45543891e-02,\n",
       "        -1.85420050e-03,  7.84115773e-03, -6.65393844e-02,\n",
       "         1.03258686e-02,  1.74191371e-02, -8.78740624e-02,\n",
       "         2.79268846e-02, -4.53915335e-02,  2.07824651e-02,\n",
       "         2.51708901e-03,  2.35436521e-02, -1.94679275e-02,\n",
       "         1.08143389e-01,  2.44996533e-33, -4.92171869e-02,\n",
       "         5.52739911e-02, -5.82063943e-02,  7.36118332e-02,\n",
       "         8.26225206e-02, -5.48170879e-02,  5.65408915e-02,\n",
       "        -8.10846761e-02, -6.08424619e-02,  7.70215094e-02,\n",
       "         1.74649172e-02, -2.91636940e-02, -3.09556461e-04,\n",
       "        -2.33890340e-02, -1.25132659e-02,  2.43681800e-02,\n",
       "         1.71411950e-02, -3.64693776e-02, -3.16016972e-02,\n",
       "         6.32760376e-02, -6.57097474e-02,  8.08130130e-02,\n",
       "         4.55828384e-03,  9.78649873e-03, -7.13628083e-02,\n",
       "         1.96885169e-02,  1.75891351e-02, -7.32675716e-02,\n",
       "        -7.79645741e-02, -1.20967003e-02,  4.03927788e-02,\n",
       "        -3.85410227e-02, -3.59157994e-02,  7.29885474e-02,\n",
       "         4.50849570e-02, -6.54247589e-03,  1.25381604e-01,\n",
       "        -8.25847536e-02, -4.08581048e-02,  1.12017289e-01,\n",
       "         7.61473104e-02,  1.03330119e-02,  1.71354450e-02,\n",
       "         4.82128710e-02,  1.16558149e-02,  2.58668121e-02,\n",
       "        -3.19126397e-02, -9.09800455e-02,  1.29503747e-02,\n",
       "         5.38696200e-02, -7.14048296e-02,  3.00491545e-02,\n",
       "        -4.04645726e-02,  1.19142644e-02, -4.08065319e-02,\n",
       "        -8.09547585e-03, -6.94270432e-02, -3.67938206e-02,\n",
       "        -3.51474211e-02, -7.22307526e-03, -6.51242957e-02,\n",
       "         8.33758488e-02, -6.17542956e-03,  3.12937759e-02,\n",
       "         1.63873564e-02, -8.98951516e-02, -3.28299925e-02,\n",
       "         4.18126956e-02,  6.20299876e-02, -1.22521035e-02,\n",
       "         5.34566259e-03,  3.15773510e-03, -4.48911749e-02,\n",
       "        -2.02630926e-02, -1.91584546e-02, -4.91733328e-02,\n",
       "        -6.56887367e-02, -3.94650921e-02, -2.56791767e-02,\n",
       "        -6.50714561e-02, -2.99258418e-02, -3.75360996e-02,\n",
       "        -3.46391089e-02,  2.94933710e-02, -4.48614620e-02,\n",
       "         2.36573629e-03,  6.49279952e-02, -2.68936343e-02,\n",
       "        -1.28394645e-02,  6.94927052e-02,  5.59816621e-02,\n",
       "         2.96556689e-02,  8.96237139e-03, -2.98858844e-02,\n",
       "        -9.47064720e-03, -1.39522269e-08, -2.66483594e-02,\n",
       "        -4.30469178e-02, -2.08143033e-02,  1.59762800e-02,\n",
       "        -4.15227525e-02, -2.48432881e-03,  1.39888022e-02,\n",
       "        -6.45600557e-02, -4.32879888e-02, -2.12720800e-02,\n",
       "         4.90580536e-02,  2.94798482e-02, -4.20931578e-02,\n",
       "         2.07408108e-02,  5.63046895e-03, -1.71239376e-02,\n",
       "        -3.56707238e-02, -9.11851879e-03, -9.01415478e-03,\n",
       "         3.83853167e-02, -1.05742984e-04,  6.06444813e-02,\n",
       "         1.18664326e-03,  1.01592034e-01, -4.88770232e-02,\n",
       "         5.00244424e-02,  8.70619416e-02,  7.61166587e-02,\n",
       "         1.50395231e-03,  2.80857272e-02,  1.08622938e-01,\n",
       "         6.83618560e-02, -5.81337139e-02, -5.58396913e-02,\n",
       "         9.68817249e-03,  5.68997674e-02,  2.58675516e-02,\n",
       "        -9.54371039e-03,  7.10769892e-02,  3.44452485e-02,\n",
       "        -6.59758970e-02, -1.13343932e-02, -3.87070142e-02,\n",
       "         2.68640257e-02,  9.82067315e-04, -9.54115093e-02,\n",
       "        -5.57169393e-02, -3.99815887e-02, -1.39719807e-02,\n",
       "        -1.19603664e-01, -2.42329054e-02, -1.53067866e-02,\n",
       "        -2.19649356e-02,  1.09830045e-03,  3.76526751e-02,\n",
       "         4.10740897e-02,  4.23793867e-02, -2.38943249e-02,\n",
       "        -1.31847501e-01,  1.38901062e-02,  1.16752811e-01,\n",
       "         5.10800257e-02,  3.65838893e-02, -9.78239104e-02]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbert_loaded = SentenceTransformer(\"../models/sbert\")\n",
    "embs = sbert_loaded.encode([\"test sentence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d552e1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gozde/.pyenv/versions/3.10.6/envs/stress_sense/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9043715846994536\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Anxiety       0.83      0.87      0.85       725\n",
      "      Normal       0.99      0.93      0.96      3208\n",
      "      Stress       0.60      0.81      0.69       459\n",
      "\n",
      "    accuracy                           0.90      4392\n",
      "   macro avg       0.80      0.87      0.83      4392\n",
      "weighted avg       0.92      0.90      0.91      4392\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "y_test_enc  = le.transform(y_test)\n",
    "\n",
    "model = LogisticRegression(\n",
    "    max_iter=2000,\n",
    "    class_weight=\"balanced\",      # helpful when classes are imbalanced\n",
    "    multi_class=\"auto\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "model.fit(E_train, y_train_enc)\n",
    "\n",
    "pred = model.predict(E_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_enc, pred))\n",
    "print(classification_report(y_test_enc, pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffe12d5",
   "metadata": {},
   "source": [
    "### ðŸ‘† Probably also good enough for our use case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f280b1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "920a403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = '/Users/gozde/code/g0zzy/stress_sense/models/hybrid_sbert_logreg_model.pkl'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stress_sense",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
