{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2e378f9",
   "metadata": {},
   "source": [
    "\"Feature-based transfer learning” in NLP.\n",
    "\n",
    "* Pre-trained DL model = feature extractor.\n",
    "\n",
    "* ML algorithm = downstream task solver.\n",
    "\n",
    "HYBRID: It’s not “pure deep learning” (since you’re not training/fine-tuning the whole transformer end-to-end).\n",
    "\n",
    "It’s also not “pure machine learning” (since your features are learned by a deep neural network, not hand-crafted)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdc8cc6",
   "metadata": {},
   "source": [
    "### SBERT + Logistic Regression = Deep learning for embeddings + Machine learning for classification → a hybrid approach that’s especially effective for small/medium labeled datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bde9f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Loading the dataset\n",
    "path = \"/Users/gozde/code/g0zzy/stress_sense/raw_data/Data.csv\"\n",
    "data = pd.read_csv(path)\n",
    "\n",
    "data.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "data.dropna(inplace=True)\n",
    "data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9aac7b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def strip_urls(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove URLs (http, https, www, youtu links) from a string.\n",
    "    \"\"\"\n",
    "    # remove http/https URLs\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    # remove www.* URLs\n",
    "    text = re.sub(r\"www\\.\\S+\", \"\", text)\n",
    "    # remove youtube short links\n",
    "    text = re.sub(r\"youtu\\.be\\S+\", \"\", text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f350c2e0",
   "metadata": {},
   "source": [
    "## Cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b22f23f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.statement = data.statement.apply(strip_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59474b0a",
   "metadata": {},
   "source": [
    "## Only classify stress, anxiety and normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49a0fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Normal': 16040, 'Anxiety': 3623, 'Stress': 2296})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "TARGET = {\"Stress\", \"Anxiety\", \"Normal\"}\n",
    "\n",
    "# 1) Filter to the 3 classes\n",
    "df = data.dropna(subset=[\"statement\",\"status\"])\n",
    "df = df[df[\"status\"].isin(TARGET)].reset_index(drop=True)\n",
    "\n",
    "texts  = df[\"statement\"].tolist()\n",
    "labels = df[\"status\"].tolist()\n",
    "print(Counter(labels))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42, stratify=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fde3f523",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 549/549 [00:18<00:00, 30.38it/s] \n",
      "Batches: 100%|██████████| 138/138 [00:04<00:00, 27.89it/s]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "sbert = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Encode (normalize for cosine/logreg stability)\n",
    "E_train = sbert.encode(X_train, normalize_embeddings=True, show_progress_bar=True)\n",
    "E_test  = sbert.encode(X_test,  normalize_embeddings=True, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d552e1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gozde/.pyenv/versions/3.10.6/envs/stress_sense/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9043715846994536\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Anxiety       0.83      0.87      0.85       725\n",
      "      Normal       0.99      0.93      0.96      3208\n",
      "      Stress       0.60      0.81      0.69       459\n",
      "\n",
      "    accuracy                           0.90      4392\n",
      "   macro avg       0.80      0.87      0.83      4392\n",
      "weighted avg       0.92      0.90      0.91      4392\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "y_test_enc  = le.transform(y_test)\n",
    "\n",
    "clf = LogisticRegression(\n",
    "    max_iter=2000,\n",
    "    class_weight=\"balanced\",      # helpful when classes are imbalanced\n",
    "    multi_class=\"auto\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "clf.fit(E_train, y_train_enc)\n",
    "\n",
    "pred = clf.predict(E_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_enc, pred))\n",
    "print(classification_report(y_test_enc, pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffe12d5",
   "metadata": {},
   "source": [
    "### 👆 Probably also good enough for our use case. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stress_sense",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
