{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "244285cd",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "484e74f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "931249c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f217d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8e55369",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB # complement naive bias is better for unblanced data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d0779d",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6ae738d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51093 entries, 0 to 51092\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   statement  51093 non-null  object\n",
      " 1   status     51093 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 798.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data_df = pd.read_csv('../data/Combined Data.csv', index_col=0)\n",
    "data_df = data_df.dropna(axis=0).reset_index(drop=True)\n",
    "data_df = data_df.drop_duplicates().reset_index(drop=True)\n",
    "data_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8173e494",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79d99e13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "statement",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "status",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "clean_statement",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "a32f1889-a4bc-4178-90e9-bc37bd719725",
       "rows": [
        [
         "0",
         "oh my gosh",
         "Anxiety",
         "oh my gosh"
        ],
        [
         "1",
         "trouble sleeping, confused mind, restless heart. All out of tune",
         "Anxiety",
         "trouble sleeping confused mind restless heart all out of tune"
        ],
        [
         "2",
         "All wrong, back off dear, forward doubt. Stay in a restless and restless place",
         "Anxiety",
         "all wrong back off dear forward doubt stay in a restless and restless place"
        ],
        [
         "3",
         "I've shifted my focus to something else but I'm still worried",
         "Anxiety",
         "ive shifted my focus to something else but im still worried"
        ],
        [
         "4",
         "I'm restless and restless, it's been a month now, boy. What do you mean?",
         "Anxiety",
         "im restless and restless it been a month now boy what do you mean"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement</th>\n",
       "      <th>status</th>\n",
       "      <th>clean_statement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oh my gosh</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>oh my gosh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trouble sleeping, confused mind, restless hear...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>trouble sleeping confused mind restless heart ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All wrong, back off dear, forward doubt. Stay ...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>all wrong back off dear forward doubt stay in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I've shifted my focus to something else but I'...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>ive shifted my focus to something else but im ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm restless and restless, it's been a month n...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>im restless and restless it been a month now b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           statement   status  \\\n",
       "0                                         oh my gosh  Anxiety   \n",
       "1  trouble sleeping, confused mind, restless hear...  Anxiety   \n",
       "2  All wrong, back off dear, forward doubt. Stay ...  Anxiety   \n",
       "3  I've shifted my focus to something else but I'...  Anxiety   \n",
       "4  I'm restless and restless, it's been a month n...  Anxiety   \n",
       "\n",
       "                                     clean_statement  \n",
       "0                                         oh my gosh  \n",
       "1  trouble sleeping confused mind restless heart ...  \n",
       "2  all wrong back off dear forward doubt stay in ...  \n",
       "3  ive shifted my focus to something else but im ...  \n",
       "4  im restless and restless it been a month now b...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocessing(sentence):\n",
    "    # Removing whitespaces\n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    # Lowercasing\n",
    "    sentence = sentence.lower()\n",
    "\n",
    "    # Removing numbers\n",
    "    sentence = ''.join(char for char in sentence if not char.isdigit())\n",
    "\n",
    "    # Removing punctuation\n",
    "    for punctuation in string.punctuation:\n",
    "        sentence = sentence.replace(punctuation, '')\n",
    "\n",
    "    # Tokenizing\n",
    "    tokenized = word_tokenize(sentence)\n",
    "\n",
    "    # Lemmatizing\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized = [lemmatizer.lemmatize(word) for word in tokenized]\n",
    "    cleaned_sentence = \" \".join(lemmatized)\n",
    "    return cleaned_sentence\n",
    "data_df['clean_statement'] = data_df['statement'].apply(preprocessing)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49761eac",
   "metadata": {},
   "source": [
    "# test train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79374542",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data_df[\"clean_statement\"], data_df[\"status\"], test_size=test_size, stratify=data_df[\"status\"], random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47671ffd",
   "metadata": {},
   "source": [
    "# preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59fe01b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_unscaledX = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(max_features=5000, ngram_range=(1, 2))),\n",
    "])\n",
    "pipe_scaledX = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(max_features=5000, ngram_range=(1, 2))),\n",
    "    ('scaler',StandardScaler(with_mean=False))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794ad26e",
   "metadata": {},
   "source": [
    "# modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d94e50",
   "metadata": {},
   "source": [
    "## possible candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0650f136",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'log_clf':LogisticRegression(random_state=42, max_iter=1000),\n",
    "                           'RF_clf': RandomForestClassifier(random_state=42, n_estimators=100, max_depth=20),\n",
    "                           #'svm_clf':SVC(kernel='sigmoid',class_weight='balanced',max_iter=200),\n",
    "                           'svm_clf': SVC(kernel='linear',class_weight='balanced',max_iter=1000),\n",
    "                           'C_NB_clf':ComplementNB(alpha=1)\n",
    "\n",
    "}\n",
    "param_grids = {\n",
    "        'log_clf': {\n",
    "            'classifier__C': [0.1, 1.0, 10.0],\n",
    "            'classifier__max_iter': [1000, 2000],\n",
    "            'preprocessing__vectorizer__max_features': [5000, 8000, 10000]\n",
    "        },\n",
    "        'RF_clf': {\n",
    "            'classifier__n_estimators': [100, 200],\n",
    "            'classifier__max_depth': [10, 20, None],\n",
    "            'preprocessing__vectorizer__max_features': [5000, 8000, 10000]\n",
    "        },\n",
    "        'C_NB_clf': {\n",
    "            'classifier__alpha': [0.1, 1, 5.0, 10.0],\n",
    "            'preprocessing__vectorizer__max_features': [5000, 8000, 10000]\n",
    "        },\n",
    "        'svm_clf': {\n",
    "            'classifier__C': [0.1, 1.0, 5,0, 10.0],\n",
    "            'classifier__max_iter': [1000, 2000]\n",
    "        }\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6666cf3e",
   "metadata": {},
   "source": [
    "### grid searching over all model candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a952870",
   "metadata": {},
   "source": [
    "#### saving best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db624a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pickle\n",
    "def save_model(grid_search_result,model_name, X_test, y_test):\n",
    "    \"\"\"Save the best model in pickle file, also save the classification report\"\"\"\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    # save model\n",
    "    best_model = grid_search_result.best_estimator_\n",
    "    best_hyperparameter = grid_search_result.best_params_\n",
    "    model_file_name = timestamp + '_' + model_name +'_model' + '.pkl'\n",
    "    parameter_file_name = timestamp + '_' + model_name+'_hyperparameters' + '.pkl'\n",
    "    result_file_name = timestamp + '_' + model_name+'Sresult' + '.pkl'\n",
    "\n",
    "    with open(model_file_name,'wb') as f:\n",
    "        pickle.dump(best_model,f)\n",
    "    with open(parameter_file_name,'wb') as f:\n",
    "        pickle.dump(best_hyperparameter,f)\n",
    "\n",
    "    # Save full result\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    result = classification_report(y_test, y_pred)\n",
    "    with open(result_file_name, 'wb') as f:\n",
    "        pickle.dump(result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8beb4092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_clf\n",
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "             Anxiety       0.78      0.71      0.74       725\n",
      "             Bipolar       0.86      0.63      0.73       500\n",
      "          Depression       0.68      0.73      0.70      3019\n",
      "              Normal       0.86      0.97      0.91      3208\n",
      "Personality disorder       0.83      0.27      0.41       179\n",
      "              Stress       0.67      0.41      0.51       459\n",
      "            Suicidal       0.70      0.65      0.67      2129\n",
      "\n",
      "            accuracy                           0.76     10219\n",
      "           macro avg       0.77      0.62      0.67     10219\n",
      "        weighted avg       0.76      0.76      0.75     10219\n",
      "\n",
      "RF_clf\n",
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sanju/.pyenv/versions/3.10.6/envs/venv_stress_sense1/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      precision    recall  f1-score   support\n",
      "\n",
      "             Anxiety       0.81      0.48      0.60       725\n",
      "             Bipolar       0.92      0.32      0.47       500\n",
      "          Depression       0.56      0.80      0.66      3019\n",
      "              Normal       0.81      0.96      0.88      3208\n",
      "Personality disorder       1.00      0.06      0.11       179\n",
      "              Stress       0.84      0.07      0.13       459\n",
      "            Suicidal       0.72      0.50      0.59      2129\n",
      "\n",
      "            accuracy                           0.69     10219\n",
      "           macro avg       0.81      0.45      0.49     10219\n",
      "        weighted avg       0.73      0.69      0.67     10219\n",
      "\n",
      "svm_clf\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sanju/.pyenv/versions/3.10.6/envs/venv_stress_sense1/lib/python3.10/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/sanju/.pyenv/versions/3.10.6/envs/venv_stress_sense1/lib/python3.10/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/sanju/.pyenv/versions/3.10.6/envs/venv_stress_sense1/lib/python3.10/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/sanju/.pyenv/versions/3.10.6/envs/venv_stress_sense1/lib/python3.10/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/sanju/.pyenv/versions/3.10.6/envs/venv_stress_sense1/lib/python3.10/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/sanju/.pyenv/versions/3.10.6/envs/venv_stress_sense1/lib/python3.10/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/sanju/.pyenv/versions/3.10.6/envs/venv_stress_sense1/lib/python3.10/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/sanju/.pyenv/versions/3.10.6/envs/venv_stress_sense1/lib/python3.10/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/sanju/.pyenv/versions/3.10.6/envs/venv_stress_sense1/lib/python3.10/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/sanju/.pyenv/versions/3.10.6/envs/venv_stress_sense1/lib/python3.10/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/sanju/.pyenv/versions/3.10.6/envs/venv_stress_sense1/lib/python3.10/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/sanju/.pyenv/versions/3.10.6/envs/venv_stress_sense1/lib/python3.10/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/sanju/.pyenv/versions/3.10.6/envs/venv_stress_sense1/lib/python3.10/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/sanju/.pyenv/versions/3.10.6/envs/venv_stress_sense1/lib/python3.10/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/sanju/.pyenv/versions/3.10.6/envs/venv_stress_sense1/lib/python3.10/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/sanju/.pyenv/versions/3.10.6/envs/venv_stress_sense1/lib/python3.10/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/sanju/.pyenv/versions/3.10.6/envs/venv_stress_sense1/lib/python3.10/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/sanju/.pyenv/versions/3.10.6/envs/venv_stress_sense1/lib/python3.10/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/sanju/.pyenv/versions/3.10.6/envs/venv_stress_sense1/lib/python3.10/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/sanju/.pyenv/versions/3.10.6/envs/venv_stress_sense1/lib/python3.10/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/sanju/.pyenv/versions/3.10.6/envs/venv_stress_sense1/lib/python3.10/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/sanju/.pyenv/versions/3.10.6/envs/venv_stress_sense1/lib/python3.10/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/sanju/.pyenv/versions/3.10.6/envs/venv_stress_sense1/lib/python3.10/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/sanju/.pyenv/versions/3.10.6/envs/venv_stress_sense1/lib/python3.10/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/sanju/.pyenv/versions/3.10.6/envs/venv_stress_sense1/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "6 fits failed out of a total of 30.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sanju/.pyenv/versions/3.10.6/envs/venv_stress_sense1/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/sanju/.pyenv/versions/3.10.6/envs/venv_stress_sense1/lib/python3.10/site-packages/sklearn/base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/home/sanju/.pyenv/versions/3.10.6/envs/venv_stress_sense1/lib/python3.10/site-packages/sklearn/pipeline.py\", line 662, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/home/sanju/.pyenv/versions/3.10.6/envs/venv_stress_sense1/lib/python3.10/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/home/sanju/.pyenv/versions/3.10.6/envs/venv_stress_sense1/lib/python3.10/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/sanju/.pyenv/versions/3.10.6/envs/venv_stress_sense1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'C' parameter of SVC must be a float in the range (0.0, inf]. Got 0 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/sanju/.pyenv/versions/3.10.6/envs/venv_stress_sense1/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.62831086 0.66189985 0.60434975 0.62462923 0.58460487 0.60804716\n",
      "        nan        nan 0.58383779 0.6169935 ]\n",
      "  warnings.warn(\n",
      "/home/sanju/.pyenv/versions/3.10.6/envs/venv_stress_sense1/lib/python3.10/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      precision    recall  f1-score   support\n",
      "\n",
      "             Anxiety       0.62      0.69      0.65       725\n",
      "             Bipolar       0.64      0.64      0.64       500\n",
      "          Depression       0.56      0.61      0.59      3019\n",
      "              Normal       0.87      0.82      0.85      3208\n",
      "Personality disorder       0.55      0.35      0.43       179\n",
      "              Stress       0.43      0.39      0.41       459\n",
      "            Suicidal       0.53      0.51      0.52      2129\n",
      "\n",
      "            accuracy                           0.65     10219\n",
      "           macro avg       0.60      0.57      0.58     10219\n",
      "        weighted avg       0.65      0.65      0.65     10219\n",
      "\n",
      "C_NB_clf\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "             Anxiety       0.48      0.81      0.60       725\n",
      "             Bipolar       0.64      0.67      0.65       500\n",
      "          Depression       0.70      0.55      0.62      3019\n",
      "              Normal       0.78      0.79      0.79      3208\n",
      "Personality disorder       0.92      0.31      0.46       179\n",
      "              Stress       0.57      0.21      0.31       459\n",
      "            Suicidal       0.61      0.75      0.68      2129\n",
      "\n",
      "            accuracy                           0.67     10219\n",
      "           macro avg       0.67      0.59      0.59     10219\n",
      "        weighted avg       0.69      0.67      0.67     10219\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fold  = StratifiedKFold(3)\n",
    "best_models_hyperparameters=dict()\n",
    "best_models_f1=dict()\n",
    "\n",
    "for (model_name,clf) in models.items():\n",
    "    print(model_name)\n",
    "    #make pipeline\n",
    "    if model_name == 'svm_clf':\n",
    "        pipe = Pipeline([('preprocessing',pipe_scaledX),\n",
    "                     ('classifier',models[model_name])])\n",
    "    else:\n",
    "        pipe = Pipeline([('preprocessing',pipe_unscaledX),\n",
    "                     ('classifier',models[model_name])])\n",
    "\n",
    "    #grid search\n",
    "    grid_search = GridSearchCV(\n",
    "        pipe,\n",
    "        param_grid=param_grids[model_name],\n",
    "        cv=fold,\n",
    "        scoring='f1_weighted',\n",
    "        n_jobs=-1,\n",
    "        verbose=1)\n",
    "    #fit\n",
    "    grid_search.fit(X_train,y_train)\n",
    "\n",
    "    #evaluate model\n",
    "    best_model =  grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    print(classification_report(y_true=y_test,y_pred=y_pred))\n",
    "\n",
    "    #calculate f1 score\n",
    "    f1_weighted = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    # save result in current session\n",
    "    best_models_hyperparameters[model_name] = grid_search.best_params_\n",
    "    best_models_f1[model_name] = f1_weighted\n",
    "\n",
    "    #save pickle files\n",
    "    save_model(grid_search,model_name,X_test,y_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
